model:
  random_seed: 42
  downscale_factor: 2
  readout_factor: 4
  saliency_map_factor: 4
  include_previous_x: true
  include_previous_y: true
  included_durations: []
  included_previous_fixations: [-1, -2, -3, -4]
  features:
    features1:
      type: "deepgaze_pytorch.features.identity.Identity"
      used_features:
        - output
  saliency_network:
    input_channels: 1
    layers: []
  scanpath_network:
    _type: torch.nn.Sequential
    _args:
    - _type: collections.OrderedDict
      _args:
      - - - encoding0
          - _type: "deepgaze_pytorch.layers.FlexibleScanpathHistoryEncoding"
            in_fixations: 4
            channels_per_fixation: 3
            out_channels: 128
            kernel_size: [1, 1]
            bias: True
        - - softplus0
          - _type: "torch.nn.Softplus"
        - - layernorm1
          - _type: deepgaze_pytorch.layers.LayerNorm
            _args: [128]
        - - conv1
          - _type: "torch.nn.Conv2d"
            _args: [128, 16, [1, 1]]
            bias: False
        - - bias1
          - _type: "deepgaze_pytorch.layers.Bias"
            _args: [16]
        - - softplus1
          - _type: "torch.nn.Softplus"
  fixation_selection_network:
    input_channels: [1, 16]
    layers:
    - name: conv1
      channels: 128
      layer_norm: True
      batch_norm: False
      activation_fn: softplus
    - name: conv2
      channels: 16
      layer_norm: True
      batch_norm: False
      activation_fn: softplus
    - name: conv3
      channels: 1
      activation_fn: null
      bias: False

training:
  optimizer:
    type: torch.optim.Adam
    params:
      lr: 0.001
  lr_scheduler:
    type: torch.optim.lr_scheduler.MultiStepLR
    params:
      milestones: [3, 6, 9, 12, 15, 18, 21, 24]
  batch_size: 4
  iteration_element: fixation
  averaging_element: image
  training_dataset_ratio_per_epoch: 0.1
  validation_epochs: 10

  parts:

# Order 4

  - name: training
    iteration_element: deepgaze_vs_scenewalk.deepgaze_tooling.FixationDatasetWithEmpiricalDensities
    torch_dataset_options:
      empirical_density_model:
        _type: pysaliency.HDF5Model
        stimuli:
          _type: pysaliency.read_hdf5
          source: COCO-Freeview_stimuli_all.hdf5
          cached: False
        filename: pseudo_crossvalidated_gold_standard.hdf5
        caching: False
    # model:
      # fixated_scopes:
      # - "saliency_network.layernorm0"
      # - "saliency_network.conv0"
      # - "saliency_network.bias0"
      # - "saliency_network.layernorm1"
      # - "saliency_network.conv1"
      # - "saliency_network.bias1"

    lr_scheduler:
      type: torch.optim.lr_scheduler.MultiStepLR
      params:
        milestones: [100, 200, 300, 310, 320, 330, 340, 350]
        #milestones: [20, 40, 60, 70, 80, 90, 100, 110]
    train_dataset: &train_dataset
        stimuli: pysaliency_datasets/COCO-Freeview/stimuli_train.hdf5
        fixations: pysaliency_datasets/COCO-Freeview/fixations_train.hdf5
        filters:
        - type: filter_fixations_by_number
          parameters:
            intervals:
            - [1, 1000]
        - type: remove_out_of_stimulus_fixations
        centerbias: centerbias_train.hdf5
    val_dataset: &val_dataset
        stimuli: pysaliency_datasets/COCO-Freeview/stimuli_validation.hdf5
        fixations: pysaliency_datasets/COCO-Freeview/fixations_validation.hdf5
        filters:
        - type: filter_fixations_by_number
          parameters:
            intervals:
            - [1, 1000]
        - type: remove_out_of_stimulus_fixations
        centerbias: centerbias_validation.hdf5

      #startwith: "{root_directory}/MIT1003_spatial/crossval-{crossval_folds}-{fold_no}/final.pth"
    evaluation:
     compute_metrics:
       metrics: ['IG', 'LL', 'AUC', 'NSS']
       datasets: ['validation']
    # final_cleanup:
    #   cleanup_checkpoints: true
  # - name: finetuning
  #   model:
  #     included_previous_fixations: [-1, -2, -3, -4]
  #     scanpath_network:
  #       _type: torch.nn.Sequential
  #       _args:
  #       - _type: collections.OrderedDict
  #         _args:
  #         - - - encoding0
  #             - _type: "deepgaze_pytorch.layers.FlexibleScanpathHistoryEncoding"
  #               in_fixations: 4
  #               channels_per_fixation: 3
  #               out_channels: 128
  #               kernel_size: [1, 1]
  #               bias: True
  #           - - softplus0
  #             - _type: "torch.nn.Softplus"
  #           - - layernorm1
  #             - _type: deepgaze_pytorch.layers.LayerNorm
  #               _args: [128]
  #           - - conv1
  #             - _type: "torch.nn.Conv2d"
  #               _args: [128, 16, [1, 1]]
  #               bias: False
  #           - - bias1
  #             - _type: "deepgaze_pytorch.layers.Bias"
  #               _args: [16]
  #           - - softplus1
  #             - _type: "torch.nn.Softplus"
  #   optimizer:
  #     params:
  #       lr: 0.00001
  #   train_dataset: *train_dataset
  #   centerbias: centerbias.hdf5
  #   crossvalidation:
  #     folds: 10
  #     val_folds: 1
  #     test_folds: 1
  #   startwith: "{root_directory}/MIT1003_order4_fixed_vgg_readout/crossval-{crossval_folds}-{fold_no}/final.pth"
  #   evaluation:
  #     compute_metrics:
  #       metrics: ['IG', 'LL', 'AUC', 'NSS']
  #       datasets: ['training', 'validation', 'test']
  #   #final_cleanup:
  #   #  cleanup_checkpoints: true
